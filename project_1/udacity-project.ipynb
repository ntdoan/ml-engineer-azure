{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275788035
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: azure-ml-engineer\n",
      "Azure region: northeurope\n",
      "Resource group: azure-ml-engineer-resource\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "ws = Workspace.get(name=\"azure-ml-engineer\")\n",
    "exp = Experiment(workspace=ws, name=\"udacity-project\")\n",
    "\n",
    "\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      #'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "gather": {
     "logged": 1598275788675
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "\n",
      "Running\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "# TODO: Create compute cluster\n",
    "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
    "# max_nodes should be no greater than 4.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "cpu_cluster_name = \"vm-azureml-experiment\"\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
    "                                                           max_nodes=4)\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform\n",
    "from azureml.train.hyperdrive import choice, PrimaryMetricGoal\n",
    "from azureml.core.script_run_config import ScriptRunConfig\n",
    "from azureml.train.estimator import Estimator\n",
    "import os\n",
    "\n",
    "# Specify parameter sampler\n",
    "### YOUR CODE HERE ###\n",
    "params_sampling = RandomParameterSampling({ \n",
    "    \"C\": choice([0.1, 0.5, 1]), \n",
    "    \"max_iter\": choice([100, 200, 300, 400, 500]), \n",
    "}) \n",
    "\n",
    "\n",
    "# Specify a Policy\n",
    "policy = BanditPolicy(evaluation_interval=100, slack_factor=0.2)\n",
    "\n",
    "if \"training\" not in os.listdir():\n",
    "    os.mkdir(\"./training\")\n",
    "\n",
    "# Create a SKLearn estimator for use with train.py\n",
    "### YOUR CODE HERE ###\n",
    "# sklearn class is deprecated. Use ScriptRunConfig instead. \n",
    "run_config = ScriptRunConfig(\n",
    "    source_directory=\"./\", \n",
    "    script=\"train.py\", \n",
    "    arguments=None, \n",
    "    compute_target=cpu_cluster_name, \n",
    "    environment=Environment.get(workspace=ws, name='AzureML-Scikit-learn-0.20.3'), \n",
    ")\n",
    "\n",
    "\n",
    "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
    "hyperdrive_config = HyperDriveConfig(\n",
    "    hyperparameter_sampling=params_sampling, \n",
    "    primary_metric_name=\"Accuracy\", \n",
    "    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "    max_total_runs=100, \n",
    "    policy=policy, \n",
    "    run_config=run_config, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
    "### YOUR CODE HERE ###\n",
    "exp = Experiment(ws, \"azureml-project1-hypertuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run = exp.submit(hyperdrive_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best run and save the model from that run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive.run import HyperDriveRun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `run_id` corresponding to the run with the highest accuracy was identified using the azureml studio interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'--C': '1', '--max_iter': '300'}\n"
     ]
    }
   ],
   "source": [
    "remote_run = HyperDriveRun(\n",
    "    experiment=Experiment(ws, \"azureml-project1-hypertuning\"), \n",
    "    run_id=\"HD_c9af2ef4-6287-4985-b0d5-fbeee818e522\"\n",
    ")\n",
    "\n",
    "best_run = remote_run.get_best_run_by_primary_metric()\n",
    "\n",
    "parameter_values = best_run.get_details()['runDefinition']['arguments']\n",
    "best_parameters = dict(zip(parameter_values[::2], parameter_values[1::2]))\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train.py` script was modified so that it persists the fitted model if `model_dir` and `model_name` are provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception (pyOpenSSL 20.0.0 (/anaconda/envs/azureml_py36/lib/python3.6/site-packages), Requirement.parse('pyopenssl<20.0.0'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyOpenSSL 20.0.0 (/anaconda/envs/azureml_py36/lib/python3.6/site-packages), Requirement.parse('pyopenssl<20.0.0'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.PipelineRun = azureml.pipeline.core.run:PipelineRun._from_dto with exception (pyOpenSSL 20.0.0 (/anaconda/envs/azureml_py36/lib/python3.6/site-packages), Requirement.parse('pyopenssl<20.0.0'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.ReusedStepRun = azureml.pipeline.core.run:StepRun._from_reused_dto with exception (pyOpenSSL 20.0.0 (/anaconda/envs/azureml_py36/lib/python3.6/site-packages), Requirement.parse('pyopenssl<20.0.0'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.StepRun = azureml.pipeline.core.run:StepRun._from_dto with exception (pyOpenSSL 20.0.0 (/anaconda/envs/azureml_py36/lib/python3.6/site-packages), Requirement.parse('pyopenssl<20.0.0'), {'azureml-core'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint azureml.scriptrun = azureml.core.script_run:ScriptRun._from_run_dto with exception (pyOpenSSL 20.0.0 (/anaconda/envs/azureml_py36/lib/python3.6/site-packages), Requirement.parse('pyopenssl<20.0.0')).\n",
      "Attempted to log scalar metric Regularization Strength::\n",
      "1.0\n",
      "Attempted to log scalar metric Max iterations::\n",
      "300\n",
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "Attempted to log scalar metric Accuracy:\n",
      "0.9100606952363436\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 89, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 79, in main\n",
      "    if args.model_name & args.model_dir:\n",
      "TypeError: unsupported operand type(s) for &: 'str' and 'str'\n"
     ]
    }
   ],
   "source": [
    "!python train.py --C 1 --max_iter 300 --model_dir ./ --model_name best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "# Create TabularDataset using TabularDatasetFactory\n",
    "# Data is available at: \n",
    "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "file_path = \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\" \n",
    "dataset = TabularDatasetFactory.from_delimited_files(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for the AutoML run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a comparison with the hyperparameter tunning run, we also clean the data using the `clean_data` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598275726969
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from train import clean_data\n",
    "\n",
    "# Use the clean_data function to clean your data.\n",
    "x, y = clean_data(dataset)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.33, random_state=1234\n",
    ")\n",
    "\n",
    "training_data = x_train.copy()\n",
    "training_data[\"y\"] = y_train\n",
    "\n",
    "validation_data = x_test.copy()\n",
    "validation_data[\"y\"] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we register the training data and validation as datasets to be used later by the AutoML run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "datastore = Datastore.get(ws, 'workspaceblobstore')\n",
    "\n",
    "Dataset.Tabular.register_pandas_dataframe(\n",
    "    dataframe=training_data, \n",
    "    name='bank_market_automl_training_set', \n",
    "    target=datastore\n",
    ")\n",
    "\n",
    "Dataset.Tabular.register_pandas_dataframe(\n",
    "    dataframe=validation_data, \n",
    "    name='bank_market_automl_validation_set', \n",
    "    target=datastore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# Set parameters for AutoMLConfig\n",
    "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
    "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
    "# Azure tenant, which will incur personal costs.\n",
    "automl_config = AutoMLConfig(\n",
    "    experiment_timeout_minutes=30,\n",
    "    compute_target=cpu_cluster_name,\n",
    "    task=\"classification\",\n",
    "    primary_metric=\"accuracy\",\n",
    "    training_data=Dataset.get_by_name(ws, 'bank_market_automl_training_set'),\n",
    "    validation_data=Dataset.get_by_name(ws, 'bank_market_automl_validation_set'),\n",
    "    label_column_name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit your automl run\n",
    "run = Experiment(ws, \"azureml-autoML-2\")\n",
    "### YOUR CODE HERE ###\n",
    "run.submit(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `run_id` corresponding to the run that returned the best model, based on accuracy, was identified using azureml studio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=2, read=3, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fb92be57470>: Failed to establish a new connection: [Errno 111] Connection refused',)': /history/v1.0/subscriptions/961a3854-0219-4fb6-a13b-5592b17a0dae/resourceGroups/azure-ml-engineer-resource/providers/Microsoft.MachineLearningServices/workspaces/azure-ml-engineer/experiments:query\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>azureml-autoML-2</td><td>AutoML_cbb0382a-bc54-4e5e-9280-bff27fe15ee2</td><td>automl</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/azureml-autoML-2/runs/AutoML_cbb0382a-bc54-4e5e-9280-bff27fe15ee2?wsid=/subscriptions/961a3854-0219-4fb6-a13b-5592b17a0dae/resourcegroups/azure-ml-engineer-resource/workspaces/azure-ml-engineer\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: azureml-autoML-2,\n",
       "Id: AutoML_cbb0382a-bc54-4e5e-9280-bff27fe15ee2,\n",
       "Type: automl,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "remote_run = AutoMLRun(experiment=ws.experiments['azureml-autoML-2'], run_id='AutoML_cbb0382a-bc54-4e5e-9280-bff27fe15ee2')\n",
    "remote_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('datatransformer',\n",
      "                 DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
      "                                 feature_sweeping_config=None,\n",
      "                                 feature_sweeping_timeout=None,\n",
      "                                 featurization_config=None, force_text_dnn=None,\n",
      "                                 is_cross_validation=None,\n",
      "                                 is_onnx_compatible=None, logger=None,\n",
      "                                 observer=None, task=None, working_dir=None)),\n",
      "                ('prefittedsoftvotingclassifier',...\n",
      "                                                                                                multi_class='ovr',\n",
      "                                                                                                n_jobs=1,\n",
      "                                                                                                penalty='l1',\n",
      "                                                                                                random_state=None,\n",
      "                                                                                                solver='saga',\n",
      "                                                                                                tol=0.0001,\n",
      "                                                                                                verbose=0,\n",
      "                                                                                                warm_start=False))],\n",
      "                                                                     verbose=False))],\n",
      "                                               flatten_transform=None,\n",
      "                                               weights=[0.09090909090909091,\n",
      "                                                        0.2727272727272727,\n",
      "                                                        0.09090909090909091,\n",
      "                                                        0.09090909090909091,\n",
      "                                                        0.09090909090909091,\n",
      "                                                        0.09090909090909091,\n",
      "                                                        0.09090909090909091,\n",
      "                                                        0.09090909090909091,\n",
      "                                                        0.09090909090909091]))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "best_run, fitted_model = remote_run.get_output()\n",
    "print(fitted_model)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
